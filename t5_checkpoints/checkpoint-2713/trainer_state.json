{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2713,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.018429782528566162,
      "grad_norm": 1.2773523330688477,
      "learning_rate": 4.9698980218700083e-05,
      "loss": 5.4159,
      "step": 50
    },
    {
      "epoch": 0.036859565057132324,
      "grad_norm": 0.773535430431366,
      "learning_rate": 4.939181717655732e-05,
      "loss": 3.6389,
      "step": 100
    },
    {
      "epoch": 0.055289347585698485,
      "grad_norm": 0.7981192469596863,
      "learning_rate": 4.908465413441455e-05,
      "loss": 3.4313,
      "step": 150
    },
    {
      "epoch": 0.07371913011426465,
      "grad_norm": 0.6978963017463684,
      "learning_rate": 4.8777491092271785e-05,
      "loss": 3.3298,
      "step": 200
    },
    {
      "epoch": 0.09214891264283082,
      "grad_norm": 0.7759546637535095,
      "learning_rate": 4.847032805012901e-05,
      "loss": 3.3619,
      "step": 250
    },
    {
      "epoch": 0.11057869517139697,
      "grad_norm": 0.7568705677986145,
      "learning_rate": 4.8163165007986244e-05,
      "loss": 3.2831,
      "step": 300
    },
    {
      "epoch": 0.12900847769996315,
      "grad_norm": 0.6799579858779907,
      "learning_rate": 4.7856001965843474e-05,
      "loss": 3.2067,
      "step": 350
    },
    {
      "epoch": 0.1474382602285293,
      "grad_norm": 0.5349483489990234,
      "learning_rate": 4.75488389237007e-05,
      "loss": 3.153,
      "step": 400
    },
    {
      "epoch": 0.16586804275709546,
      "grad_norm": 0.7624514102935791,
      "learning_rate": 4.724167588155793e-05,
      "loss": 3.1923,
      "step": 450
    },
    {
      "epoch": 0.18429782528566163,
      "grad_norm": 0.8336101770401001,
      "learning_rate": 4.693451283941516e-05,
      "loss": 3.1732,
      "step": 500
    },
    {
      "epoch": 0.2027276078142278,
      "grad_norm": 0.9387838244438171,
      "learning_rate": 4.66273497972724e-05,
      "loss": 3.178,
      "step": 550
    },
    {
      "epoch": 0.22115739034279394,
      "grad_norm": 0.909470796585083,
      "learning_rate": 4.632018675512962e-05,
      "loss": 3.1487,
      "step": 600
    },
    {
      "epoch": 0.2395871728713601,
      "grad_norm": 0.8461583256721497,
      "learning_rate": 4.601302371298686e-05,
      "loss": 3.1323,
      "step": 650
    },
    {
      "epoch": 0.2580169553999263,
      "grad_norm": 0.7184539437294006,
      "learning_rate": 4.5705860670844087e-05,
      "loss": 3.1017,
      "step": 700
    },
    {
      "epoch": 0.27644673792849245,
      "grad_norm": 0.7614105939865112,
      "learning_rate": 4.5398697628701316e-05,
      "loss": 3.2316,
      "step": 750
    },
    {
      "epoch": 0.2948765204570586,
      "grad_norm": 0.6786227822303772,
      "learning_rate": 4.5091534586558545e-05,
      "loss": 3.0008,
      "step": 800
    },
    {
      "epoch": 0.3133063029856248,
      "grad_norm": 0.6684582233428955,
      "learning_rate": 4.4784371544415775e-05,
      "loss": 3.1015,
      "step": 850
    },
    {
      "epoch": 0.3317360855141909,
      "grad_norm": 0.7357620596885681,
      "learning_rate": 4.447720850227301e-05,
      "loss": 2.9619,
      "step": 900
    },
    {
      "epoch": 0.3501658680427571,
      "grad_norm": 0.8081740736961365,
      "learning_rate": 4.417004546013024e-05,
      "loss": 2.9309,
      "step": 950
    },
    {
      "epoch": 0.36859565057132326,
      "grad_norm": 0.6598358750343323,
      "learning_rate": 4.386288241798747e-05,
      "loss": 3.0565,
      "step": 1000
    },
    {
      "epoch": 0.3870254330998894,
      "grad_norm": 0.7431583404541016,
      "learning_rate": 4.35557193758447e-05,
      "loss": 3.0639,
      "step": 1050
    },
    {
      "epoch": 0.4054552156284556,
      "grad_norm": 12.191261291503906,
      "learning_rate": 4.324855633370193e-05,
      "loss": 2.9345,
      "step": 1100
    },
    {
      "epoch": 0.42388499815702174,
      "grad_norm": 0.642913281917572,
      "learning_rate": 4.2941393291559165e-05,
      "loss": 2.9943,
      "step": 1150
    },
    {
      "epoch": 0.4423147806855879,
      "grad_norm": 0.6810293793678284,
      "learning_rate": 4.263423024941639e-05,
      "loss": 2.9873,
      "step": 1200
    },
    {
      "epoch": 0.4607445632141541,
      "grad_norm": 0.559029221534729,
      "learning_rate": 4.2327067207273624e-05,
      "loss": 3.0121,
      "step": 1250
    },
    {
      "epoch": 0.4791743457427202,
      "grad_norm": 0.7281472086906433,
      "learning_rate": 4.2019904165130853e-05,
      "loss": 2.9706,
      "step": 1300
    },
    {
      "epoch": 0.4976041282712864,
      "grad_norm": 0.8445867896080017,
      "learning_rate": 4.171274112298808e-05,
      "loss": 2.9015,
      "step": 1350
    },
    {
      "epoch": 0.5160339107998526,
      "grad_norm": 0.5654202699661255,
      "learning_rate": 4.140557808084531e-05,
      "loss": 2.9434,
      "step": 1400
    },
    {
      "epoch": 0.5344636933284187,
      "grad_norm": 0.6119396686553955,
      "learning_rate": 4.109841503870255e-05,
      "loss": 2.8656,
      "step": 1450
    },
    {
      "epoch": 0.5528934758569849,
      "grad_norm": 0.7492556571960449,
      "learning_rate": 4.079125199655978e-05,
      "loss": 2.8317,
      "step": 1500
    },
    {
      "epoch": 0.5713232583855511,
      "grad_norm": 0.5814321637153625,
      "learning_rate": 4.048408895441701e-05,
      "loss": 2.9019,
      "step": 1550
    },
    {
      "epoch": 0.5897530409141172,
      "grad_norm": 0.6305776238441467,
      "learning_rate": 4.017692591227424e-05,
      "loss": 2.8512,
      "step": 1600
    },
    {
      "epoch": 0.6081828234426834,
      "grad_norm": 0.6496685743331909,
      "learning_rate": 3.9869762870131466e-05,
      "loss": 2.8306,
      "step": 1650
    },
    {
      "epoch": 0.6266126059712496,
      "grad_norm": 0.5742912888526917,
      "learning_rate": 3.95625998279887e-05,
      "loss": 2.8608,
      "step": 1700
    },
    {
      "epoch": 0.6450423884998157,
      "grad_norm": 0.5767165422439575,
      "learning_rate": 3.9255436785845925e-05,
      "loss": 2.8948,
      "step": 1750
    },
    {
      "epoch": 0.6634721710283819,
      "grad_norm": 0.6612684726715088,
      "learning_rate": 3.894827374370316e-05,
      "loss": 2.8112,
      "step": 1800
    },
    {
      "epoch": 0.681901953556948,
      "grad_norm": 0.5990036725997925,
      "learning_rate": 3.864111070156039e-05,
      "loss": 2.8635,
      "step": 1850
    },
    {
      "epoch": 0.7003317360855142,
      "grad_norm": 0.9205067157745361,
      "learning_rate": 3.833394765941762e-05,
      "loss": 2.8299,
      "step": 1900
    },
    {
      "epoch": 0.7187615186140803,
      "grad_norm": 0.7069308757781982,
      "learning_rate": 3.802678461727485e-05,
      "loss": 2.8889,
      "step": 1950
    },
    {
      "epoch": 0.7371913011426465,
      "grad_norm": 0.5094358921051025,
      "learning_rate": 3.771962157513208e-05,
      "loss": 2.8024,
      "step": 2000
    },
    {
      "epoch": 0.7556210836712127,
      "grad_norm": 0.6244612336158752,
      "learning_rate": 3.7412458532989315e-05,
      "loss": 2.8496,
      "step": 2050
    },
    {
      "epoch": 0.7740508661997788,
      "grad_norm": 0.6748182773590088,
      "learning_rate": 3.7105295490846545e-05,
      "loss": 2.8246,
      "step": 2100
    },
    {
      "epoch": 0.792480648728345,
      "grad_norm": 0.7174170017242432,
      "learning_rate": 3.6798132448703774e-05,
      "loss": 2.826,
      "step": 2150
    },
    {
      "epoch": 0.8109104312569112,
      "grad_norm": 0.523895800113678,
      "learning_rate": 3.6490969406561004e-05,
      "loss": 2.7808,
      "step": 2200
    },
    {
      "epoch": 0.8293402137854773,
      "grad_norm": 1.0455775260925293,
      "learning_rate": 3.618380636441823e-05,
      "loss": 2.8807,
      "step": 2250
    },
    {
      "epoch": 0.8477699963140435,
      "grad_norm": 0.6181491613388062,
      "learning_rate": 3.587664332227547e-05,
      "loss": 2.8208,
      "step": 2300
    },
    {
      "epoch": 0.8661997788426097,
      "grad_norm": 0.5946605205535889,
      "learning_rate": 3.556948028013269e-05,
      "loss": 2.8167,
      "step": 2350
    },
    {
      "epoch": 0.8846295613711758,
      "grad_norm": 0.5858719944953918,
      "learning_rate": 3.526231723798993e-05,
      "loss": 2.8049,
      "step": 2400
    },
    {
      "epoch": 0.903059343899742,
      "grad_norm": 0.6393921971321106,
      "learning_rate": 3.495515419584716e-05,
      "loss": 2.7678,
      "step": 2450
    },
    {
      "epoch": 0.9214891264283082,
      "grad_norm": 0.503508985042572,
      "learning_rate": 3.464799115370439e-05,
      "loss": 2.8983,
      "step": 2500
    },
    {
      "epoch": 0.9399189089568744,
      "grad_norm": 0.6633691787719727,
      "learning_rate": 3.434082811156162e-05,
      "loss": 2.7179,
      "step": 2550
    },
    {
      "epoch": 0.9583486914854404,
      "grad_norm": 0.7118969559669495,
      "learning_rate": 3.403366506941885e-05,
      "loss": 2.7696,
      "step": 2600
    },
    {
      "epoch": 0.9767784740140066,
      "grad_norm": 0.5705476403236389,
      "learning_rate": 3.372650202727608e-05,
      "loss": 2.8249,
      "step": 2650
    },
    {
      "epoch": 0.9952082565425728,
      "grad_norm": 0.6078850030899048,
      "learning_rate": 3.3419338985133305e-05,
      "loss": 2.7878,
      "step": 2700
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.55727481842041,
      "eval_runtime": 105.757,
      "eval_samples_per_second": 22.807,
      "eval_steps_per_second": 2.856,
      "step": 2713
    }
  ],
  "logging_steps": 50,
  "max_steps": 8139,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5873834183884800.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
